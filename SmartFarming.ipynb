{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SmartFarming",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/safin777/SmartFarming/blob/main/SmartFarming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF7BugLRC2FR"
      },
      "source": [
        "Downloading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxXRYeDWC7_Y",
        "outputId": "e9f8cac9-5ee9-495a-a497-da4deb04a17e"
      },
      "source": [
        "# Download a file based on its file ID.\n",
        "file_id = '18DbC6Xj4NP-hLzI14WuMaAEyq482vNfn'\n",
        "\n",
        "# Download dataset\n",
        "!gdown https://drive.google.com/uc?id={file_id}\n",
        "\n",
        "# Unzip the downloaded file\n",
        "!unzip -q PlantVillage.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=18DbC6Xj4NP-hLzI14WuMaAEyq482vNfn\n",
            "To: /content/PlantVillage.zip\n",
            "866MB [00:04, 195MB/s]\n",
            "replace PlantVillage/train/Apple___Apple_scab/01a66316-0e98-4d3b-a56f-d78752cd043f___FREC_Scab 3003.JPG? [y]es, [n]o, [A]ll, [N]one, [r]ename: None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optyadXvEJ1M"
      },
      "source": [
        "Importing the libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDeK9Fp1EPzR"
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from os import listdir\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88N0aobBHunK"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZTfMsnLH1sM"
      },
      "source": [
        "Initializing a few parameters required for the image dataset preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_P-_yzCMH5FK"
      },
      "source": [
        "# Dimension of resized image\n",
        "DEFAULT_IMAGE_SIZE = tuple((256, 256))\n",
        "\n",
        "# Number of images used to train the model\n",
        "N_IMAGES = 100\n",
        "\n",
        "# Path to the dataset folder\n",
        "root_dir = './PlantVillage'\n",
        "\n",
        "train_dir = os.path.join(root_dir, 'train')\n",
        "val_dir = os.path.join(root_dir, 'val')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBRWwojQKPS0"
      },
      "source": [
        "We use the function convert_image_to_array to resize an image to the size DEFAULT_IMAGE_SIZE we defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAnE8pEHUVno"
      },
      "source": [
        "def convert_image_to_array(image_dir):\n",
        "    try:\n",
        "        image = cv2.imread(image_dir)\n",
        "        if image is not None:\n",
        "            image = cv2.resize(image, DEFAULT_IMAGE_SIZE)   \n",
        "            return img_to_array(image)\n",
        "        else:\n",
        "            return np.array([])\n",
        "    except Exception as e:\n",
        "        print(f\"Error : {e}\")\n",
        "        return None\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIQ09v5oYeex"
      },
      "source": [
        "Here, we load the training data images by traversing through all the folders and converting all the images and labels into separate lists respectively.\n",
        "\n",
        "NOTE: We use a small portion of the entire dataset due to the computing limitations. Tweak N_IMAGES to include entire dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfEwZ13SYtU2",
        "outputId": "dd4ab445-11f0-408d-aebf-9a405e900f34"
      },
      "source": [
        "image_list, label_list =[], []\n",
        "\n",
        "try: \n",
        "  print(\"[INFO] Loading image......\")\n",
        "  plant_disease_folder_list = listdir(train_dir)\n",
        "\n",
        "  for plant_disease_folder in plant_disease_folder_list:\n",
        "    print(f\"[INFO] Processing {plant_disease_folder}......\")\n",
        "    plant_disease_image_list = listdir(f\"{train_dir}/{plant_disease_folder}/\")\n",
        "\n",
        "    for image in plant_disease_image_list[:N_IMAGES]:\n",
        "      image_directory = f\"{train_dir}/{plant_disease_folder}/{image}\"\n",
        "      if image_directory.endswith(\".jpg\")==True or image_directory.endswith(\".JPG\")==True:\n",
        "                image_list.append(convert_image_to_array(image_directory))\n",
        "                label_list.append(plant_disease_folder)\n",
        "\n",
        "    print(\"[INFO] Image loading completed\")  \n",
        "except Exception as e:\n",
        "    print(f\"Error : {e}\")\n",
        "\n",
        "# Transform the loaded training image data into numpy array\n",
        "np_image_list = np.array(image_list, dtype=np.float16) / 225.0\n",
        "print()\n",
        "\n",
        "# Check the number of images loaded for training\n",
        "image_len = len(image_list)\n",
        "print(f\"Total number of images: {image_len}\")\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Loading image......\n",
            "[INFO] Processing Tomato___Target_Spot......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Blueberry___healthy......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Cherry_(including_sour)___Powdery_mildew......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Tomato___Late_blight......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Pepper,_bell___healthy......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Apple___healthy......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Corn_(maize)___healthy......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Squash___Powdery_mildew......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Corn_(maize)___Northern_Leaf_Blight......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Soybean___healthy......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Tomato___Early_blight......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Raspberry___healthy......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Tomato___Septoria_leaf_spot......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Tomato___Spider_mites Two-spotted_spider_mite......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Apple___Cedar_apple_rust......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Orange___Haunglongbing_(Citrus_greening)......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Tomato___Bacterial_spot......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Apple___Apple_scab......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Tomato___Leaf_Mold......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Corn_(maize)___Common_rust_......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Apple___Black_rot......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Pepper,_bell___Bacterial_spot......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Cherry_(including_sour)___healthy......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Tomato___Tomato_Yellow_Leaf_Curl_Virus......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Peach___Bacterial_spot......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Tomato___healthy......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Potato___Late_blight......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Grape___healthy......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Potato___healthy......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing background......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Grape___Black_rot......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Grape___Esca_(Black_Measles)......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Grape___Leaf_blight_(Isariopsis_Leaf_Spot)......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Potato___Early_blight......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Strawberry___Leaf_scorch......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Strawberry___healthy......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Peach___healthy......\n",
            "[INFO] Image loading completed\n",
            "[INFO] Processing Tomato___Tomato_mosaic_virus......\n",
            "[INFO] Image loading completed\n",
            "\n",
            "Total number of images: 3900\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0UXk3C-lB9u"
      },
      "source": [
        "Examine the labels/classes in the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSMdx6X2lGNu",
        "outputId": "0e4bd275-0610-4a5a-d866-de5811bce45e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "label_binarizer = LabelBinarizer()\n",
        "image_labels = label_binarizer.fit_transform(label_list)\n",
        "\n",
        "pickle.dump(label_binarizer,open('plant_disease_label_transform.pkl', 'wb'))\n",
        "n_classes = len(label_binarizer.classes_)\n",
        "\n",
        "print(\"Total number of classes: \", n_classes)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total number of classes:  39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "km-YZCW1lOG1"
      },
      "source": [
        "#Augment and Split Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeCctSIklUOM"
      },
      "source": [
        "Using ImageDataGenerator to augment data by performing various operations on the training images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkZWxu4_le2m"
      },
      "source": [
        "augment = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,\n",
        "                             height_shift_range=0.1, shear_range=0.2, \n",
        "                             zoom_range=0.2, horizontal_flip=True, \n",
        "                             fill_mode=\"nearest\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg3jU-KjnKCH"
      },
      "source": [
        "Splitting the data into training and test sets for validation purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySYZcMvXnP73",
        "outputId": "8d3b5568-4feb-4ab3-dc95-74996f34072f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"[INFO] Splitting data to train and test...\")\n",
        "x_train, x_test, y_train, y_test = train_test_split(np_image_list, image_labels, test_size=0.2, random_state = 42) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Splitting data to train and test...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8KZoJMToYKu"
      },
      "source": [
        "# Build Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dElm6rdpGBH"
      },
      "source": [
        "Defining the hyperparameters of the plant disease classification model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y-2V2_toX4e"
      },
      "source": [
        "EPOCHS = 30\n",
        "STEPS = 100\n",
        "LR = 1e-3\n",
        "BATCH_SIZE = 32\n",
        "WIDTH = 256\n",
        "HEIGHT = 256\n",
        "DEPTH = 3"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF0nOhybqkSA"
      },
      "source": [
        "Creating a sequential model and adding Convolutional, Normalization, Pooling, Dropout and Activation layers at the appropriate positions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1H6PAGXqkwg",
        "outputId": "b2aa2198-7753-4aae-caa2-e3b4908adb6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = Sequential()\n",
        "inputShape = (HEIGHT, WIDTH, DEPTH)\n",
        "chanDim = -1\n",
        "\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "    inputShape = (DEPTH, HEIGHT, WIDTH)\n",
        "    chanDim = 1\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding=\"same\",input_shape=inputShape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization(axis=chanDim))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(n_classes))\n",
        "model.add(Activation(\"softmax\"))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 256, 256, 32)      896       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 256, 256, 32)      0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 256, 256, 32)      128       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 85, 85, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 85, 85, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 85, 85, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 85, 85, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 85, 85, 64)        256       \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 85, 85, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 85, 85, 64)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 85, 85, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 42, 42, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 42, 42, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 42, 42, 128)       73856     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 42, 42, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 42, 42, 128)       512       \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 42, 42, 128)       147584    \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 42, 42, 128)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 42, 42, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 21, 21, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 21, 21, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 56448)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              57803776  \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 39)                39975     \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 39)                0         \n",
            "=================================================================\n",
            "Total params: 58,127,271\n",
            "Trainable params: 58,124,391\n",
            "Non-trainable params: 2,880\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASH_putsupPy"
      },
      "source": [
        "# Train Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6pJZ19ouslK"
      },
      "source": [
        "We initialize Adam optimizer with learning rate and decay parameters.\n",
        "\n",
        "Also, we choose the type of loss and metrics for the model and compile it for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzUVsIQBu0kx",
        "outputId": "a61673e6-8bf9-4674-892a-e980c3d4ae09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Initialize optimizer\n",
        "opt = Adam(lr=LR, decay=LR / EPOCHS)\n",
        "\n",
        "# Compile model\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
        "\n",
        "# Train model\n",
        "print(\"[INFO] Training network...\")\n",
        "history = model.fit_generator(augment.flow(x_train, y_train, batch_size=BATCH_SIZE),\n",
        "                              validation_data=(x_test, y_test),\n",
        "                              steps_per_epoch=len(x_train) // BATCH_SIZE,\n",
        "                              epochs=EPOCHS, \n",
        "                              verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Training network...\n",
            "WARNING:tensorflow:From <ipython-input-11-6d88faf22259>:13: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use Model.fit, which supports generators.\n",
            "Epoch 1/30\n",
            "97/97 [==============================] - 758s 8s/step - loss: 0.1053 - accuracy: 0.2549 - val_loss: 0.3169 - val_accuracy: 0.0474\n",
            "Epoch 2/30\n",
            "97/97 [==============================] - 763s 8s/step - loss: 0.0850 - accuracy: 0.3957 - val_loss: 0.3672 - val_accuracy: 0.0372\n",
            "Epoch 3/30\n",
            "97/97 [==============================] - 761s 8s/step - loss: 0.0681 - accuracy: 0.5087 - val_loss: 0.3036 - val_accuracy: 0.0526\n",
            "Epoch 4/30\n",
            "97/97 [==============================] - 746s 8s/step - loss: 0.0588 - accuracy: 0.5719 - val_loss: 0.1828 - val_accuracy: 0.1949\n",
            "Epoch 5/30\n",
            "97/97 [==============================] - 760s 8s/step - loss: 0.0571 - accuracy: 0.5787 - val_loss: 0.2119 - val_accuracy: 0.2244\n",
            "Epoch 6/30\n",
            "97/97 [==============================] - 756s 8s/step - loss: 0.0480 - accuracy: 0.6392 - val_loss: 0.0697 - val_accuracy: 0.5603\n",
            "Epoch 7/30\n",
            "97/97 [==============================] - 763s 8s/step - loss: 0.0434 - accuracy: 0.6700 - val_loss: 0.0944 - val_accuracy: 0.5346\n",
            "Epoch 8/30\n",
            "97/97 [==============================] - 767s 8s/step - loss: 0.0450 - accuracy: 0.6713 - val_loss: 0.0613 - val_accuracy: 0.6064\n",
            "Epoch 9/30\n",
            "97/97 [==============================] - 763s 8s/step - loss: 0.0398 - accuracy: 0.7034 - val_loss: 0.1526 - val_accuracy: 0.3179\n",
            "Epoch 10/30\n",
            "97/97 [==============================] - 762s 8s/step - loss: 0.0376 - accuracy: 0.7157 - val_loss: 0.1260 - val_accuracy: 0.4244\n",
            "Epoch 11/30\n",
            "97/97 [==============================] - 762s 8s/step - loss: 0.0376 - accuracy: 0.7277 - val_loss: 0.0571 - val_accuracy: 0.6269\n",
            "Epoch 12/30\n",
            "97/97 [==============================] - 759s 8s/step - loss: 0.0352 - accuracy: 0.7374 - val_loss: 0.0683 - val_accuracy: 0.5513\n",
            "Epoch 13/30\n",
            "97/97 [==============================] - 757s 8s/step - loss: 0.0312 - accuracy: 0.7775 - val_loss: 0.1115 - val_accuracy: 0.5333\n",
            "Epoch 14/30\n",
            "97/97 [==============================] - 761s 8s/step - loss: 0.0287 - accuracy: 0.7824 - val_loss: 0.0399 - val_accuracy: 0.7333\n",
            "Epoch 15/30\n",
            "97/97 [==============================] - 758s 8s/step - loss: 0.0274 - accuracy: 0.7895 - val_loss: 0.0985 - val_accuracy: 0.5372\n",
            "Epoch 16/30\n",
            "97/97 [==============================] - 761s 8s/step - loss: 0.0256 - accuracy: 0.8057 - val_loss: 0.0729 - val_accuracy: 0.6013\n",
            "Epoch 17/30\n",
            "97/97 [==============================] - 762s 8s/step - loss: 0.0265 - accuracy: 0.8038 - val_loss: 0.1230 - val_accuracy: 0.4603\n",
            "Epoch 18/30\n",
            "97/97 [==============================] - 760s 8s/step - loss: 0.0237 - accuracy: 0.8157 - val_loss: 0.0922 - val_accuracy: 0.5115\n",
            "Epoch 19/30\n",
            "97/97 [==============================] - 759s 8s/step - loss: 0.0234 - accuracy: 0.8264 - val_loss: 0.0333 - val_accuracy: 0.7846\n",
            "Epoch 20/30\n",
            "97/97 [==============================] - 757s 8s/step - loss: 0.0218 - accuracy: 0.8429 - val_loss: 0.0349 - val_accuracy: 0.8013\n",
            "Epoch 21/30\n",
            "97/97 [==============================] - 761s 8s/step - loss: 0.0220 - accuracy: 0.8374 - val_loss: 0.0638 - val_accuracy: 0.6538\n",
            "Epoch 22/30\n",
            "97/97 [==============================] - 763s 8s/step - loss: 0.0213 - accuracy: 0.8416 - val_loss: 0.0782 - val_accuracy: 0.6064\n",
            "Epoch 23/30\n",
            "97/97 [==============================] - 767s 8s/step - loss: 0.0191 - accuracy: 0.8569 - val_loss: 0.1176 - val_accuracy: 0.5064\n",
            "Epoch 24/30\n",
            "97/97 [==============================] - 759s 8s/step - loss: 0.0186 - accuracy: 0.8620 - val_loss: 0.0348 - val_accuracy: 0.8077\n",
            "Epoch 25/30\n",
            "97/97 [==============================] - 765s 8s/step - loss: 0.0184 - accuracy: 0.8630 - val_loss: 0.0634 - val_accuracy: 0.6603\n",
            "Epoch 26/30\n",
            "97/97 [==============================] - 769s 8s/step - loss: 0.0170 - accuracy: 0.8692 - val_loss: 0.1921 - val_accuracy: 0.3449\n",
            "Epoch 27/30\n",
            "97/97 [==============================] - 761s 8s/step - loss: 0.0201 - accuracy: 0.8478 - val_loss: 0.1389 - val_accuracy: 0.4436\n",
            "Epoch 28/30\n",
            "97/97 [==============================] - 764s 8s/step - loss: 0.0190 - accuracy: 0.8659 - val_loss: 0.1468 - val_accuracy: 0.4538\n",
            "Epoch 29/30\n",
            "97/97 [==============================] - 755s 8s/step - loss: 0.0179 - accuracy: 0.8679 - val_loss: 0.0393 - val_accuracy: 0.7872\n",
            "Epoch 30/30\n",
            "97/97 [==============================] - 735s 8s/step - loss: 0.0153 - accuracy: 0.8892 - val_loss: 0.0499 - val_accuracy: 0.7397\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9u4H1KYPugvN"
      },
      "source": [
        "#Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfeLukPEugbl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}